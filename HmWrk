#Task 1

#Robots.txt

#Download and save to file robots.txt from wikipedia, twitter websites etc. 

import requests

def download_robots_txt(url, save_path):
    # Make a GET request to the website's robots.txt URL
    response = requests.get(url + "/robots.txt")
    
    if response.status_code == 200:
        # Save the content to a file
        with open(save_path, 'w') as file:
            file.write(response.text)
        print(f"robots.txt from {url} downloaded and saved successfully.")
    else:
        print(f"Failed to download robots.txt from {url}.")

# Example usage
websites = {
    "Wikipedia": "https://en.wikipedia.org",
    "Twitter": "https://twitter.com",
    # Add more websites here
}

for name, url in websites.items():
    save_file_path = f"{name.lower()}_robots.txt"
    download_robots_txt(url, save_file_path)





#Task 2

#Load data

#Download all comments from a subreddit of your choice using URL: https://api.pushshift.io/reddit/comment/search/ . 

#As a result, store all comments in chronological order in JSON and dump it to a file.

 

#Task 3

#The Weather app

#Write a console application which takes as an input a city name and returns current weather in the format of your choice. For the current task, you can choose any weather API or website or use openweathermap.org 
